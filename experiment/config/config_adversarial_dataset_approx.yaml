
# ========================================================================= #
# CONFIG                                                                    #
# ========================================================================= #

defaults:
  - run_logging: wandb_fast
  - run_location: griffin
  - run_launcher: local
  # entries in this file override entries from default lists
  - _self_

settings:
  job:
    user: 'author_12045'
    project: 'DELETE'
    name_prefix: 'B32'
    name: '${settings.job.name_prefix}-${adv_system.dataset_name}_${adv_system.adversarial_mode}_${adv_system.samples_sort_mode}_aw${adv_system.loss_adversarial_weight}_${adv_system.sampler_name}_s${trainer.max_steps}_${adv_system.optimizer_name}_lr${adv_system.optimizer_lr}_wd${adv_system.optimizer_kwargs.weight_decay}_b${settings.dataset.batch_size}_${settings.exp.save_dtype}'
    seed: 424242
  exp:
    show_every_n_steps: 1000
    # saving
    rel_save_dir: 'out/adversarial_data_approx/'
    save_prefix: 'PREFIX'
    save_model: FALSE
    save_data: FALSE
    save_dtype: float16
  dataset:
    batch_size: 32

trainer:
  # same as defaults: - run_length: ...
  # - 15000 takes 40 mins with batch size 512 (heartofgold, 12 workers)
  # - 50000 takes 33 mins with batch size 256 (griffin, 16 workers)
  max_steps: 15000
  max_epochs: 15000

adv_system:
  ### IMPORTANT SETTINGS ###
  #   best:
  #     - close_p_random_n
  #   note: sampler_name (adversarial_mode=invert_margin_0.005)
  #     - random_swap_manhattan: worst [no inversion before 5k]     (probability of encountering close is too low, don't use! ++easiest to implement)
  #     - close_p_random_n:      good  [inversion before 5k]        (easier to implement)
  #     - close_p_random_n_bb:   good  [inversion before 5k]        (hard to implement, but pretty much the same as close_p_random_n)
  #     - same_k:                bad   [no inversion before 5k]     (probability of encountering close is too low, don't use! --harder to implement, better guarantees than random_swap_manhattan)
  #     - same_k_close:          ok    [almost inversion before 5k] (harder to implement)
  #     - same_k1_close:         best  [inversion well before 5 k]  (easier to implement)
  #   note: sampler_name (adversarial_mode=self)
  #     - close_p_random_n:      seems better based on plot of fdists vs overlap (converges better, but loss is higher which makes sense)
  #     - same_k1_close:         seems worse based on plot of fdists vs overlap (seems to maintain original shape more, might hinder d9rdfghjkiu765rdfg? not actually tested)
  sampler_name:      'close_p_random_n'      # [random_swap_manhattan, close_p_random_n, same_k1_close]
  samples_sort_mode: 'swap'                  # [none, swap, sort_inorder, sort_reverse]
  dataset_name:      'smallnorb'             # [cars3d, smallnorb, dsprites, shapes3d, xysquares_8x8_mini]
  adversarial_mode:  'triplet_margin_0.1'    # [self, invert_margin_0.05, invert_margin_0.005] invert, invert_unbounded

  ### OTHER SETTINGS ###
  # optimizer options
  optimizer_name: 'adam'
  optimizer_lr: 2e-3
  optimizer_kwargs:
     weight_decay: 1e-5
  # dataset config options
  dataset_batch_size: ${dataloader.batch_size}  # x3
  dataset_num_workers: ${dataloader.num_workers}
  data_root: ${dsettings.storage.data_root}
  data_load_into_memory: FALSE  # I don't think this is truly multi-threaded, possible lock on array access?
  # adversarial loss options
  adversarial_swapped: FALSE
  adversarial_masking: FALSE  # can produce weird artefacts that look like they might go against the training process, eg. improve d9rdfghjkiu765rdfg on dsprites, not actually checked by trianing model on this.
  adversarial_top_k:   NULL   # NULL or range(1, batch_size)
  pixel_loss_mode:    'mse'
  # loss extras
  loss_adversarial_weight:  10.0
  loss_out_of_bounds_weight: 1.0   # not really needed -- if this is too high it struggles to "invert"
  loss_same_stats_weight:    0.0   # not really needed
  loss_similarity_weight:    1.0   # important
  # model settings
  model_type: 'ae_conv64'  # ae_conv64, ae_linear, ae_conv64norm
  model_mask_mode: 'none'  # std, diff, none
  model_weight_init: 'xavier_normal'   # [xavier_normal, default]
  # logging settings
  logging_scale_imgs: FALSE


# ========================================================================= #
# OLD EXPERIMENTS                                                           #
# ========================================================================= #


# EXPERIMENT SWEEP:
# -m framework.sampler_name=close_p_random_n framework.adversarial_mode=self,invert_margin_0.005 framework.dataset_name=dsprites,shapes3d,cars3d,smallnorb
# -m framework.loss_adversarial_weight=100.0 framework.sampler_name=same_k1_close framework.adversarial_mode=self2,self framework.dataset_name=dsprites,shapes3d,cars3d,smallnorb

# EXPERIMENT INDIVIDUALS:
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=self                 framework.dataset_name=dsprites
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=self                 framework.dataset_name=shapes3d
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=self                 framework.dataset_name=cars3d
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=self                 framework.dataset_name=smallnorb

# framework.sampler_name=close_p_random_n  framework.adversarial_mode=invert_margin_0.005  framework.dataset_name=dsprites
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=invert_margin_0.005  framework.dataset_name=shapes3d
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=invert_margin_0.005  framework.dataset_name=cars3d
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=invert_margin_0.005  framework.dataset_name=smallnorb
#
# # 3dshapes does not seem to want to invert...
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=invert_margin_0.01  framework.dataset_name=shapes3d
# framework.sampler_name=close_p_random_n  framework.adversarial_mode=invert_margin_0.10  framework.dataset_name=shapes3d

# NEW EXPERIMENT:
# -m framework.sampler_name=same_k1_close,close_p_random_n framework.adversarial_mode=invert_margin_0.05 framework.dataset_name=dsprites,shapes3d,smallnorb,cars3d
# - continue
#   DONE: -m framework.sampler_name=same_k1_close,close_p_random_n framework.adversarial_mode=invert_margin_0.05 framework.dataset_name=smallnorb,cars3d
#   DOING: -m framework.sampler_name=close_p_random_n framework.adversarial_mode=invert_margin_0.05 framework.dataset_name=smallnorb,cars3d
#   TODO: -m framework.sampler_name=close_p_random_n framework.adversarial_mode=invert_margin_0.05 framework.dataset_name=cars3d,smallnorb

# NEW EXPERIMENT 2:
# -m framework.sampler_name=same_k1_close,close_p_random_n framework.adversarial_mode=invert_margin_0.05 framework.loss_out_of_bounds_weight=1000.0 framework.dataset_name=dsprites,shapes3d,smallnorb,cars3d

# NEW EXPERIMENT 3:
# -m framework.sampler_name=same_k1_close framework.adversarial_mode=invert_margin_0.05 framework.loss_out_of_bounds_weight=10000.0 framework.dataset_name=shapes3d,dsprites,cars3d,smallnorb
